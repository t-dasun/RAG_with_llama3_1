{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Required Libraries\n",
    "# !pip install -qU transformers torch accelerate bitsandbytes\n",
    "# !pip install -qU langchain langchain_community langchain_huggingface\n",
    "# !pip install -qU sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc55484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Collecting pypdf',\n",
       " '  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)',\n",
       " 'Downloading pypdf-6.0.0-py3-none-any.whl (310 kB)',\n",
       " '\\x1b[?25l   \\x1b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/310.5 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
       " '\\x1b[2K   \\x1b[38;2;249;38;114m━━━\\x1b[0m\\x1b[38;2;249;38;114m╸\\x1b[0m\\x1b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m30.7/310.5 kB\\x1b[0m \\x1b[31m1.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
       " '\\x1b[2K   \\x1b[38;2;249;38;114m━━━━━━━━━━━\\x1b[0m\\x1b[38;2;249;38;114m╸\\x1b[0m\\x1b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m92.2/310.5 kB\\x1b[0m \\x1b[31m1.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
       " '\\x1b[2K   \\x1b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[38;5;237m╺\\x1b[0m\\x1b[38;5;237m━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m174.1/310.5 kB\\x1b[0m \\x1b[31m1.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
       " '\\x1b[2K   \\x1b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[38;2;249;38;114m╸\\x1b[0m \\x1b[32m307.2/310.5 kB\\x1b[0m \\x1b[31m2.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
       " '\\x1b[2K   \\x1b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m310.5/310.5 kB\\x1b[0m \\x1b[31m2.2 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
       " '\\x1b[?25hInstalling collected packages: pypdf',\n",
       " 'Successfully installed pypdf-6.0.0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!pip install pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bd9cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dasun/venvs/ai_test/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF file: ./knowledge/DasunPathirage.pdf\n",
      "Loading TXT file: ./knowledge/cv.txt\n",
      "Loaded 3 documents from knowledge base.\n",
      "Split into 19 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19559/909863854.py:31: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pypdf\n",
    "\n",
    "# Step 1: Walk through the knowledge directory\n",
    "documents = []\n",
    "for root, _, files in os.walk(\"./knowledge\"):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if file.lower().endswith(\".pdf\"):\n",
    "            print(f\"Loading PDF file: {file_path}\")\n",
    "            pdf_loader = PyPDFLoader(file_path)\n",
    "            documents.extend(pdf_loader.load())\n",
    "        elif file.lower().endswith(\".txt\"):\n",
    "            print(f\"Loading TXT file: {file_path}\")\n",
    "            text_loader = TextLoader(file_path)\n",
    "            documents.extend(text_loader.load())\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents from knowledge base.\")\n",
    "\n",
    "# Step 2: Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split into {len(chunks)} chunks.\")\n",
    "\n",
    "# Step 3: Embed + store in FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
    "print(\"Vector store created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89b7cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ./knowledge/DasunPathirage.pdf, Length: C++\n",
      "Python\n",
      "Verilog\n",
      "+94714092010\n",
      "dasunpathirage@gmail.com\n",
      "www.linkedin.com/in/dasun-pathirage/\n",
      "127/1A/7 Kadawatha, Sri Lanka\n",
      "CONTACT PROFILE\n",
      "SKILLS\n",
      "EDUCATION\n",
      "WORK EXPERIENCE\n",
      "Programming Languages: Proficient in C/C++,\n",
      "Python, Verilog/System Verilog,\n",
      "HTML/CSS/JavaScript, Ladder Programming\n",
      "Software Development: VSCode, Visual Studio,\n",
      "Spring Boot, Atmel Studio, Vivado/HLS/SDK,\n",
      "Android Studio, MPLAB, MATLAB, ARM\n",
      "Development Studio\n",
      "Technical Expertise: FPGA, Linux/MacOS, Git, Jira,\n",
      "Confluence, Machine Learning, Analytical\n",
      "Thinking, Problem Solving, Creativity/Leadership\n",
      "MSc in Advanced Software EngineeringUniversity of Westminster\n",
      "Reading\n",
      "BSc (Hons) in Electronic &\n",
      "Telecommunication EngineeringSri Lanka Technological Campus \n",
      "2016-2020\n",
      "Senior Software Engineer\n",
      "Sagence AI, California, US (Remote from Accelr Sri Lanka)\n",
      "Member of the Analog Inference back-end software development team.\n",
      "Responsible for the development an mapping tool capable of automatically\n",
      "mapping a given neural network on to the Analog Inference data flow\n",
      "accelerator chip. Carried out experiments with new mapping policies and\n",
      "algorithms to optimize space utilization and performance. (C++)\n",
      "Managed the development, testing, and maintenance of the automated mapper\n",
      "tool and its test regression suite. (Python)\n",
      "Oversaw firmware updates and maintenance, ensuring robust and up-to-date\n",
      "system operations.(C++)\n",
      "Designed and implemented a model visualization tool tailored to the hardware-\n",
      "constrained mapping, to enhance understanding and troubleshooting\n",
      "capabilities and thereby simplify the debug process.(C++, Python)\n",
      "Developed and maintained tools for generating detailed reports on utilization,\n",
      "frames per second (FPS), and power distribution, aiding in better resource\n",
      "management. (C++)\n",
      "Created an API for a Python interface to facilitate backend mapper interactions,\n",
      "enhancing its usability and accessibility. (C++)\n",
      "Performed performance analysis using ARM Development Studio for YOLOv5,\n",
      "identifying key areas for improvement in the host side software stack.\n",
      "Mentor ACCELR team members on topics related to parallel computing and\n",
      "HPC.\n",
      "Involved in RISCV learning group in ACCELR.\n",
      "Train interns in System verilog in ACCELR\n",
      "2020-2024\n",
      "Experienced Senior Software Engineer with a robust background in embedded\n",
      "software development, C++, FPGA design, RISC-V architecture, and machine\n",
      "learning. Renowned for a quick learning curve, exceptional analytical thinking, and\n",
      "superior problem-solving abilities. Demonstrates a strong ability to drive innovative\n",
      "solutions and optimize complex systems. Adept at leading cross-functional teams,\n",
      "mentoring junior engineers, and delivering high-impact projects on time. Seeking\n",
      "opportunities to leverage my extensive skill set and contribute to cutting-edge\n",
      "technological advancements and impactful projects.\n",
      "LANGUAGES\n",
      "THARINDU DASUN PATHIRAGE\n",
      "EMBEDDED / SOFTWARE ENGINEER\n",
      "G.C.E. Advanced Level Examination \n",
      "G.C.E. Ordinary Level Examination\n",
      "St. Joseph's College, Colombo-10\n",
      "2010-2015\n",
      "Senior Consultant Engineer\n",
      "Sagence AI, California, US (Remote) 2024-Present\n",
      "Developed an automated mapping tool to optimize neural network deployment\n",
      "on the Analog Inference data flow accelerator chip, enhancing space utilization\n",
      "and performance through new mapping policies and algorithms. (C++)\n",
      "Conducted experiments and optimizations on various neural networks, including\n",
      "ResNet, YOLO, and FCN, driving significant improvements in model efficiency\n",
      "and accuracy. (C++, Python)\n",
      "Maintained the software simulators for AI chips, enhancing development\n",
      "accuracy and reducing turnaround times.(C++)\n",
      "Source: ./knowledge/DasunPathirage.pdf, Length: VOLUNTEERING\n",
      "R E F E R E N C E COURSES AND CERTIFICATIONS\n",
      "RISC-V Associate Certificate Course (Ongoing) - Linux Foundation\n",
      "Complete Modern C++ (C++11/14/17) - Udemy\n",
      "Machine Learning - Stanford University - Coursera\n",
      "Cryptography and Information Theory - University of Colorado - Coursera\n",
      "Cloud Engineering with Google Cloud - Google Cloud - Coursera\n",
      "NDG Linux Unhatched - Cisco Networking Academy\n",
      "AWS Cloud Practitioner Essentials - Amazon Web Services (AWS)\n",
      "FPGA Programming with VHDL - Pluralsight\n",
      "SSL/TLS Protocol and Handshake Process - Udemy\n",
      "Projects\n",
      "Hardware Acceleration of OpenSSL Crypto Functions using\n",
      "FPGAs\n",
      "Improved SSL/TLS connection performance with AES & RSA\n",
      "implementations. (System Verilog)\n",
      "Embedded Systems Temperature Controller System\n",
      "Developed using Atmel Studio and C language for\n",
      "ATmega328p.\n",
      "GPS Tracking System\n",
      "Implemented using ESP32 microcontroller and C language;\n",
      "developed an Android app for tracking.\n",
      "Reservation System\n",
      "Concurrently driven service reservation system that hosted\n",
      "distributed system. (Java)\n",
      "Cloud base Web for Company Product marketing \n",
      "Developed and deployed web system with CI/CD pipeline,\n",
      "and cloud automation with AWS CDK, and Git hub. \n",
      "IEEE Sri Lanka Section\n",
      "Membership Development Subcommittee\n",
      "Chairman (2020-2021)\n",
      "Committee Member, IEEE YP Sri Lanka\n",
      "Section (2020-2021)\n",
      "Co-Chairman, IEEE Sri Lanka Section SWY\n",
      "Congress (2019)\n",
      "First President, IEEE Student Branch at\n",
      "SLTC (2018-2019)\n",
      "Logistic Team Lead, IEEE Sri Lanka Section\n",
      "SWY Congress (2018-2019)\n",
      "Student Ambassador, IEEE PES HAC (2018-\n",
      "2019)\n",
      "Student Ambassador, IEEE MadC (2019)\n",
      "LEO Club SLTC\n",
      "Director, LEO Club of SLTC (2017-2018)\n",
      "Eng. Harshana Miyuranga\n",
      "Software Engineer, Accelr\n",
      "Mobile: +94710574020\n",
      "Email: hmiyurangaala@gmail.com\n",
      "Dr. Udesh S. Oruthota\n",
      "Head, School of Engineering, Sri Lanka\n",
      "Technological Campus\n",
      "Mobile: +94713351730\n",
      "Email: udesho@sltc.ac.lk\n",
      "Eng. Aruna Rajapaksha\n",
      "Hardware Architecture, Paraqum Technologies\n",
      "Mobile: +94771114541\n",
      "Email: aruna@paraqum.com\n",
      "Research\n",
      "Multi-Prime RSA Verilog Implementation Using 4-Primes\n",
      "Presented at IEEE ICIAfS 2021\n",
      "https://ieeexplore.ieee.org/document/9605975\n",
      "Developed a Slack messaging bot and an email verification system for Gmail\n",
      "using C++ with CURL, enhancing communication efficiencies.\n",
      "Automated SMS delivery using a GSM modem in C++, streamlining the\n",
      "messaging process.\n",
      "Engineered hardware accelerators for DDR memory read/write operations in\n",
      "Verilog and C++ (High-Level Synthesis), boosting system performance.\n",
      "Implemented hardware-accelerated AXI DMA IP in Verilog, enhancing data\n",
      "throughput and system reliability.\n",
      "Acquired hands-on experience in FPGA electronic design and parallel\n",
      "processing, contributing to a deeper understanding of network products and\n",
      "their applications.\n",
      "Electronic Engineering Trainee\n",
      "2018Paraqum Technologies\n",
      "FPGA Firmware Engineer\n",
      "2024Dexon Technologies, Ban Chang, Thailand (Remote from Sri Lanka)\n",
      "Worked as a contract engineer as freelancer. \n",
      "Designed and implemented a scalable SystemVerilog-based external device\n",
      "controller with SPI/QSPI interface, supporting multiple sensors with\n",
      "configurable data capture, FIFO buffering, and control/status registers.\n",
      "Enabled safe, periodic data sampling from odometers with sensor-wise enable/\n",
      "disable, data count tracking, and clean memory-mapped interface for\n",
      "integration.\n",
      "Developed FPGA firmware using SystemVerilog for a Magnetic Logging Facility\n",
      "(MLF) data-logger to collect and buffer magnetic sensor data in real-time.\n",
      "Integrated PSRAM interface logic to store high-speed magnetic sensor data\n",
      "streams efficiently within FPGA fabric.\n",
      "Utilized Lattice Radiant for synthesis and Questa Lattice for simulation and\n",
      "functional verification.\n",
      "Designed and verified data acquisition pipelines, ensuring reliable sensor data\n",
      "capture and transfer to memory under timing and resource constraints.\n",
      "Implemented state machines and memory controllers optimized for low-latency\n",
      "data access and robust sensor data logging.\n",
      "Source: ./knowledge/cv.txt, Length: Tharindu Dasun Pathirage is an experienced Senior Software Engineer with a robust background in \n",
      "embedded software development, C++, FPGA design, RISC-V architecture, and machine learning. \n",
      "He recognized for his quick learning ability, strong analytical thinking, and superior problem-solving skills. \n",
      "His experience includes developing automated mapping tools for neural network deployment on AI accelerator chips , \n",
      "designing FPGA firmware , and optimizing complex systems. he have a history of leading teams, \n",
      "mentoring junior engineers, and delivering high-impact projects.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for doc in documents:\n",
    "    print(f\"Source: {doc.metadata['source']}, Length: {(doc.page_content)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b783348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (0.34.4)\n",
      "Requirement already satisfied: filelock in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from huggingface_hub) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from huggingface_hub) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from requests->huggingface_hub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dasun/venvs/ai_test/lib/python3.12/site-packages (from requests->huggingface_hub) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "210076ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Replace \"YOUR_HF_TOKEN\" with your actual token\n",
    "# login(\"YOUR_HF_TOKEN\")\n",
    "hf_token = os.getenv(\"HUGGING_FACE_HUB_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1647e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.54s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain created and ready to use.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Phase 2 - Setting up the RAG Chain\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Hugging Face Hub Login (if not already done in terminal)\n",
    "# from huggingface_hub import login\n",
    "# login(\"YOUR_HF_TOKEN\")\n",
    "\n",
    "# Define the model ID for Llama 3.1 8B Instruct\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# model_id = \"unsloth/llama-3.1-8b-bnb-4bit\"\n",
    "\n",
    "# Use quantization to reduce memory usage\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Create a text-generation pipeline\n",
    "text_generation_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    top_p=0.9,\n",
    "    temperature=0.1, # Use low temperature for factual answers\n",
    ")\n",
    "\n",
    "# Wrap the pipeline in a LangChain object\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "# Define the RAG prompt template\n",
    "prompt_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a helpful assistant. Please answer the user's question based only on the following context. If the answer is not in the context, say you don't know. Do not use any prior knowledge.\n",
    "\n",
    "CONTEXT:\n",
    "{context}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "QUESTION:\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create the retriever from our vector store\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3}) # Retrieve top 3 chunks\n",
    "\n",
    "# Create the RAG chain using LangChain Expression Language (LCEL)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"RAG chain created and ready to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a49db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_answer(raw_output: str) -> str:\n",
    "    if \"assistant<|end_header_id|>\" in raw_output:\n",
    "        return raw_output.split(\"assistant<|end_header_id|>\")[-1].strip()\n",
    "    return raw_output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ce8b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is Dasun?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Dasun is Dasun Pathirage, an experienced Senior Software Engineer.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question: What Dasun Done in Sri Lanka Technological Campus?\n",
      "Answer: Dasun Pathirage was the Director of the LEO Club of SLTC (2017-2018) and a Student at BSc (Hons) in Electronic & Telecommunication Engineering at Sri Lanka Technological Campus from 2016-2020.\n"
     ]
    }
   ],
   "source": [
    "# Question 1: The answer is in the document.\n",
    "question1 = \"Who is Dasun?\"\n",
    "print(f\"Question: {question1}\")\n",
    "\n",
    "# Invoke the chain\n",
    "# answer1 = rag_chain.invoke(question1)\n",
    "answer1 = clean_answer(rag_chain.invoke(question1))\n",
    "print(f\"Answer: {answer1}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Question 2: The answer is NOT in the document.\n",
    "question2 = \"What Dasun Done in Sri Lanka Technological Campus?\"\n",
    "print(f\"Question: {question2}\")\n",
    "\n",
    "# Invoke the chain\n",
    "answer2 = clean_answer(rag_chain.invoke(question2))\n",
    "print(f\"Answer: {answer2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e88ee5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ACCELR is mentioned as the name of the company where Tharindu Dasun Pathirage worked as a Senior Software Engineer, and also as the name of a team (ACCELR team) that he mentored.\n"
     ]
    }
   ],
   "source": [
    "question2 = \"ACCELR?\"\n",
    "docs2 = retriever.get_relevant_documents(question2)\n",
    "context2 = \"\\n\".join([doc.page_content for doc in docs2])\n",
    "prompt_text2 = prompt.format(context=context2, question=question2)\n",
    "answer2 = clean_answer(llm.invoke(prompt_text2))\n",
    "print(f\"Answer: {answer2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
